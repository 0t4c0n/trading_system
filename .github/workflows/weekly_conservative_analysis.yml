# .github/workflows/weekly_conservative_analysis.yml
name: Enhanced Conservative Stock Analysis with Trading Levels

on:
  schedule:
    # Sábados a las 10:00 AM España (9:00 AM UTC)
    - cron: '0 9 * * 6'
  workflow_dispatch:  # Permitir ejecución manual

# PERMISOS NECESARIOS PARA GITHUB PAGES Y COMMITS
permissions:
  contents: write
  pages: write
  id-token: write

# Asegurar que solo un workflow corra a la vez
concurrency:
  group: "enhanced-conservative-analysis"
  cancel-in-progress: false

jobs:
  enhanced-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 150  # 2.5 horas para análisis completo
    
    # Configurar entorno para GitHub Pages
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Checkout código
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Historial completo para análisis de consistencia
        
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Cache dependencies mejorado
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-enhanced-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-enhanced-
          ${{ runner.os }}-pip-
        
    - name: Instalar dependencias
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Verificar archivos de configuración y estado del historial
      run: |
        echo "=== VERIFICANDO CONFIGURACIÓN MEJORADA CON HISTORIAL ==="
        if [ ! -f "current_portfolio.json" ]; then
          echo "⚠️ current_portfolio.json no encontrado - se creará ejemplo"
        else
          echo "✓ current_portfolio.json encontrado"
          echo "Posiciones actuales:"
          python3 -c "
import json
try:
    with open('current_portfolio.json', 'r') as f:
        data = json.load(f)
    positions = list(data.get('positions', {}).keys())
    print(f'📂 {len(positions)} posiciones: {positions}')
    print(f'💰 Cash disponible: \$\${data.get(\"cash\", 0):,.2f}')
except Exception as e:
    print(f'❌ Error leyendo portfolio: {e}')
          "
        fi
        
        echo ""
        echo "=== VERIFICANDO SCRIPTS PRINCIPALES ==="
        for script in "conservative_screener.py" "consistency_analyzer.py" "rotation_recommender.py" "create_weekly_report.py"; do
          if [ -f "$script" ]; then
            echo "✓ $script encontrado"
          else
            echo "❌ $script NO ENCONTRADO"
            exit 1
          fi
        done
        
        echo ""
        echo "=== ESTADO DEL HISTORIAL ACTUAL ==="
        
        # Contar archivos históricos por tipo
        hist_screening=$(ls weekly_screening_results_*.json 2>/dev/null | wc -l)
        hist_ultra=$(ls ultra_conservative_results_*.json 2>/dev/null | wc -l)
        hist_consistency=$(ls consistency_analysis_*.json 2>/dev/null | wc -l)
        hist_rotation=$(ls rotation_recommendations_*.json 2>/dev/null | wc -l)
        hist_reports=$(ls *WEEKLY_REPORT*.md 2>/dev/null | wc -l)
        
        echo "📊 Estado del historial antes del análisis:"
        echo "   - Screening históricos: $hist_screening archivos"
        echo "   - Ultra conservadores: $hist_ultra archivos"
        echo "   - Análisis consistencia: $hist_consistency archivos"
        echo "   - Recomendaciones: $hist_rotation archivos"
        echo "   - Reportes: $hist_reports archivos"
        
        # Verificar archivo actual (último análisis)
        if [ -f "weekly_screening_results.json" ]; then
          echo "✓ Último screening encontrado - será archivado automáticamente"
          python3 -c "
import json
try:
    with open('weekly_screening_results.json', 'r') as f:
        data = json.load(f)
    date = data.get('analysis_date', '')[:10]
    symbols = len(data.get('detailed_results', []))
    print(f'   📅 Fecha: {date} | 📊 {symbols} símbolos')
except:
    print('   ⚠️ Error leyendo archivo actual')
          "
        else
          echo "ℹ️ Sin screening previo - primera ejecución o análisis inicial"
        fi
        
    - name: 1. Ejecutar screening conservador con gestión de historial
      run: |
        echo "🔍 PASO 1: Screening conservador mejorado con gestión automática de historial..."
        echo "📁 El sistema archivará automáticamente el screening anterior (si existe)"
        echo "🧹 Aplicará limpieza automática de archivos antiguos"
        
        # Ejecutar screening con gestión de historial integrada
        python conservative_screener.py
        
        echo "Verificando resultados del screening con historial..."
        if [ -f "weekly_screening_results.json" ]; then
          echo "✅ Screening completado exitosamente con gestión de historial"
          python3 -c "
import json
with open('weekly_screening_results.json', 'r') as f:
    data = json.load(f)
results = data.get('detailed_results', [])
print(f'📊 {len(results)} acciones pasaron filtros conservadores mejorados')
if results:
    # Verificar si tiene el scoring mejorado
    if 'technical_score' in results[0]:
        avg_tech = sum(r.get('technical_score', 0) for r in results) / len(results)
        avg_final = sum(r.get('score', 0) for r in results) / len(results)
        avg_rr = sum(r.get('risk_reward_ratio', 0) for r in results) / len(results)
        print(f'📈 Score técnico promedio: {avg_tech:.1f}')
        print(f'🎯 Score final promedio: {avg_final:.1f}')
        print(f'⚖️ Risk/Reward promedio: {avg_rr:.1f}:1')
        print('✅ SCORING MEJORADO Y GESTIÓN DE HISTORIAL DETECTADOS')
    else:
        avg_rr = sum(r.get('risk_reward_ratio', 0) for r in results) / len(results)
        print(f'⚖️ Risk/Reward promedio: {avg_rr:.1f}:1')
    
    top_5 = [r['symbol'] for r in results[:5]]
    print(f'🏆 Top 5: {top_5}')
    
    # Verificar tipo de análisis
    analysis_type = data.get('analysis_type', 'standard')
    print(f'🔬 Tipo de análisis: {analysis_type}')
          "
        else
          echo "❌ Error en screening - archivo de resultados no encontrado"
          exit 1
        fi
      env:
        PYTHONUNBUFFERED: 1
        
    - name: 2. Analizar consistencia histórica con archivos mejorados
      run: |
        echo "📊 PASO 2: Análisis de consistencia (5 semanas) con gestión de historial..."
        echo "📁 El sistema archivará automáticamente el análisis anterior (si existe)"
        echo "🔍 Buscará archivos históricos en múltiples formatos para máxima compatibilidad"
        
        python consistency_analyzer.py
        
        if [ -f "consistency_analysis.json" ]; then
          echo "✅ Análisis de consistencia completado con gestión de historial"
          python3 -c "
import json
with open('consistency_analysis.json', 'r') as f:
    data = json.load(f)
stats = data.get('summary_stats', {})
sources = data.get('data_sources', {})
print(f'🏆 Consistent Winners: {stats.get(\"consistent_winners_count\", 0)}')
print(f'💎 Strong Candidates: {stats.get(\"strong_candidates_count\", 0)}')
print(f'🌱 Emerging Opportunities: {stats.get(\"emerging_count\", 0)}')
print(f'📊 Total símbolos únicos analizados: {stats.get(\"total_unique_symbols\", 0)}')
print(f'📚 Semanas analizadas: {data.get(\"weeks_analyzed\", 0)}')

# Mostrar fuentes de datos
hist_files = sources.get('historical_files', [])
valid_files = [f for f in hist_files if 'N/A' not in f]
print(f'📁 Archivos históricos válidos: {len(valid_files)}')
          "
        else
          echo "❌ Error en análisis de consistencia"
          exit 1
        fi
      env:
        PYTHONUNBUFFERED: 1
        
    - name: 3. Generar recomendaciones de rotación con historial
      run: |
        echo "🎯 PASO 3: Recomendaciones de rotación con análisis multifactorial y gestión de historial..."
        echo "📁 El sistema archivará automáticamente las recomendaciones anteriores (si existen)"
        
        python rotation_recommender.py
        
        if [ -f "rotation_recommendations.json" ]; then
          echo "✅ Recomendaciones de rotación completadas con gestión de historial"
          python3 -c "
import json
with open('rotation_recommendations.json', 'r') as f:
    data = json.load(f)
action = data.get('action_summary', {}).get('overall_action', 'NO_ACTION')
strong_buys = len(data.get('action_summary', {}).get('strong_buys', []))
exits = len(data.get('action_summary', {}).get('consider_exits', [])) + len(data.get('action_summary', {}).get('urgent_exits', []))
holds = len(data.get('action_summary', {}).get('holds', []))
print(f'⚡ Acción general: {action}')
print(f'🔥 Compras fuertes recomendadas: {strong_buys}')
print(f'⚠️ Salidas a considerar: {exits}')
print(f'✅ Mantener posiciones: {holds}')

# Verificar si es análisis avanzado
analysis_type = data.get('analysis_type', 'standard')
if 'advanced' in analysis_type or 'multifactor' in analysis_type:
    print('🚀 ANÁLISIS MULTIFACTORIAL AVANZADO CON HISTORIAL DETECTADO')
else:
    print('📊 Análisis estándar completado')
          "
        else
          echo "❌ Error en recomendaciones de rotación"
          exit 1
        fi
      env:
        PYTHONUNBUFFERED: 1
        
    - name: 4. Crear reporte semanal mejorado con historial
      run: |
        echo "📋 PASO 4: Generando reporte semanal mejorado con niveles de trading y gestión de historial..."
        echo "📁 El sistema gestionará automáticamente el historial de reportes"
        
        python create_weekly_report.py
        
        echo "Verificando reportes generados..."
        if [ -f "docs/data.json" ]; then
          echo "✅ Dashboard data.json generado"
          python3 -c "
import json
with open('docs/data.json', 'r') as f:
    data = json.load(f)
analysis_type = data.get('analysis_type', 'standard')
top_picks = len(data.get('top_picks', []))
print(f'📊 Tipo de análisis: {analysis_type}')
print(f'🎯 Top picks generados: {top_picks}')

# Verificar características avanzadas
features = []
if 'trading_metrics' in data:
    metrics = data['trading_metrics']
    print(f'⚖️ Avg R/R: {metrics.get(\"avg_risk_reward\", 0):.1f}:1')
    print(f'📈 Oportunidades alta calidad: {metrics.get(\"high_quality_count\", 0)}')
    features.append('Trading Metrics')

if any('take_profit' in str(pick) for pick in data.get('top_picks', [])):
    features.append('Stop/Target Dinámicos')

if any('technical_score' in str(pick) for pick in data.get('top_picks', [])):
    features.append('Scoring Avanzado')

if features:
    print(f'🚀 Características detectadas: {\" | \".join(features)}')
          "
        else
          echo "❌ Error generando dashboard data"
          exit 1
        fi
        
        # Verificar reportes Markdown
        ENHANCED_REPORT=$(ls ENHANCED_WEEKLY_REPORT_*.md 2>/dev/null | head -1)
        REGULAR_REPORT=$(ls WEEKLY_REPORT_*.md 2>/dev/null | head -1)
        
        if [ -n "$ENHANCED_REPORT" ]; then
          echo "✅ Reporte mejorado generado: $ENHANCED_REPORT"
        elif [ -n "$REGULAR_REPORT" ]; then
          echo "✅ Reporte regular generado: $REGULAR_REPORT"
        else
          echo "⚠️ No se generó reporte Markdown (puede ser normal)"
        fi
      env:
        PYTHONUNBUFFERED: 1
        
    - name: Verificar archivos generados y calidad con historial
      run: |
        echo "=== VERIFICACIÓN FINAL DE ARCHIVOS Y GESTIÓN DE HISTORIAL ==="
        
        # Archivos principales
        for file in "weekly_screening_results.json" "consistency_analysis.json" "rotation_recommendations.json" "docs/data.json"; do
          if [ -f "$file" ]; then
            size=$(stat -c%s "$file")
            echo "✅ $file (${size} bytes)"
          else
            echo "❌ $file FALTANTE"
          fi
        done
        
        # Verificar estado del historial después del análisis
        echo ""
        echo "=== ESTADO DEL HISTORIAL DESPUÉS DEL ANÁLISIS ==="
        
        hist_screening=$(ls weekly_screening_results_*.json 2>/dev/null | wc -l)
        hist_ultra=$(ls ultra_conservative_results_*.json 2>/dev/null | wc -l)
        hist_consistency=$(ls consistency_analysis_*.json 2>/dev/null | wc -l)
        hist_rotation=$(ls rotation_recommendations_*.json 2>/dev/null | wc -l)
        hist_reports=$(ls *WEEKLY_REPORT*.md 2>/dev/null | wc -l)
        
        echo "📊 Historial después del análisis:"
        echo "   - Screening históricos: $hist_screening archivos"
        echo "   - Ultra conservadores: $hist_ultra archivos"
        echo "   - Análisis consistencia: $hist_consistency archivos"
        echo "   - Recomendaciones: $hist_rotation archivos"
        echo "   - Reportes: $hist_reports archivos"
        
        # Verificar calidad de datos
        echo ""
        echo "=== VERIFICACIÓN DE CALIDAD ==="
        python3 -c "
import json
import os

def check_file_quality(filename, min_size=100):
    if not os.path.exists(filename):
        print(f'❌ {filename}: No existe')
        return False
    
    size = os.path.getsize(filename)
    if size < min_size:
        print(f'⚠️ {filename}: Muy pequeño ({size} bytes)')
        return False
    
    try:
        with open(filename, 'r') as f:
            data = json.load(f)
        print(f'✅ {filename}: JSON válido ({size} bytes)')
        return True
    except Exception as e:
        print(f'❌ {filename}: JSON inválido - {e}')
        return False

# Verificar archivos críticos
files_ok = 0
files_ok += check_file_quality('weekly_screening_results.json', 1000)
files_ok += check_file_quality('consistency_analysis.json', 500)
files_ok += check_file_quality('rotation_recommendations.json', 500)
files_ok += check_file_quality('docs/data.json', 1000)

print(f'\\n📊 Resumen: {files_ok}/4 archivos OK')
if files_ok < 3:
    print('❌ CALIDAD INSUFICIENTE - Revisar logs')
    exit(1)
else:
    print('✅ CALIDAD ACEPTABLE')
        "
        
        # Mostrar estadísticas finales
        echo ""
        echo "=== ESTADÍSTICAS FINALES CON HISTORIAL ==="
        python3 -c "
import json
from datetime import datetime

# Cargar datos principales
try:
    with open('weekly_screening_results.json', 'r') as f:
        screening = json.load(f)
    with open('consistency_analysis.json', 'r') as f:
        consistency = json.load(f)
    with open('rotation_recommendations.json', 'r') as f:
        rotation = json.load(f)
        
    # Estadísticas básicas
    results = screening.get('detailed_results', [])
    total_screened = len(results)
    winners = consistency.get('summary_stats', {}).get('consistent_winners_count', 0)
    action = rotation.get('action_summary', {}).get('overall_action', 'NO_ACTION')
    weeks_analyzed = consistency.get('weeks_analyzed', 0)
    
    print(f'📊 Total filtradas: {total_screened}')
    print(f'🏆 Consistent winners: {winners}')
    print(f'⚡ Acción requerida: {action}')
    print(f'📚 Semanas de historial analizadas: {weeks_analyzed}')
    print(f'📅 Análisis completado: {datetime.now().strftime(\"%Y-%m-%d %H:%M UTC\")}')
    
    # Verificar mejoras aplicadas
    analysis_type = screening.get('analysis_type', 'standard')
    print(f'🔬 Tipo de análisis aplicado: {analysis_type}')
    
    # Detectar características mejoradas
    features = []
    if results and 'technical_score' in results[0]:
        features.append('Scoring Avanzado')
    if results and 'rr_bonus' in str(results[0]):
        features.append('R/R Integrado')  
    if 'sustainable_momentum' in analysis_type:
        features.append('Momentum Sostenible')
    if 'timeframe' in str(screening.get('methodology', {})):
        features.append('Rangos por Timeframe')
    if 'historial' in str(consistency.get('data_sources', {})):
        features.append('Gestión de Historial')
        
    if features:
        print(f'🚀 CARACTERÍSTICAS MEJORADAS: {\", \".join(features)}')
    else:
        print('📊 Análisis estándar realizado')
        
except Exception as e:
    print(f'⚠️ Error en estadísticas finales: {e}')
        "
        
    - name: Crear resumen de commit mejorado con historial
      run: |
        echo "=== CREANDO RESUMEN DE COMMIT CON GESTIÓN DE HISTORIAL ==="
        
        REPORT_DATE=$(date +%Y-%m-%d)
        
        # Extraer información clave
        python3 -c "
import json
from datetime import datetime

try:
    # Cargar datos
    with open('weekly_screening_results.json', 'r') as f:
        screening = json.load(f)
    with open('consistency_analysis.json', 'r') as f:
        consistency = json.load(f)
    with open('rotation_recommendations.json', 'r') as f:
        rotation = json.load(f)
    
    # Extraer información
    results = screening.get('detailed_results', [])
    top_symbols = [r['symbol'] for r in results[:5]]
    winners_count = consistency.get('summary_stats', {}).get('consistent_winners_count', 0)
    action = rotation.get('action_summary', {}).get('overall_action', 'NO_ACTION')
    weeks_analyzed = consistency.get('weeks_analyzed', 0)
    
    # Métricas de trading
    trading_metrics = ''
    if results:
        if 'technical_score' in results[0]:
            avg_tech = sum(r.get('technical_score', 0) for r in results) / len(results)
            avg_final = sum(r.get('score', 0) for r in results) / len(results)
            trading_metrics = f' | Tech: {avg_tech:.0f} Final: {avg_final:.0f}'
        
        avg_rr = sum(r.get('risk_reward_ratio', 0) for r in results) / len(results)
        high_quality = len([r for r in results if r.get('risk_reward_ratio', 0) > 2.5])
        trading_metrics += f' | R/R: {avg_rr:.1f}:1 | HQ: {high_quality}'
    
    # Detectar tipo de análisis
    analysis_type = screening.get('analysis_type', 'standard')
    if 'sustainable_momentum' in analysis_type:
        analysis_label = 'Sustainable Momentum + Historial'
    elif 'enhanced' in analysis_type:
        analysis_label = 'Enhanced + Historial'
    else:
        analysis_label = 'Standard + Historial'
    
    # Crear mensaje
    with open('commit_message.txt', 'w') as f:
        f.write(f'📈 {analysis_label} Analysis $REPORT_DATE\\n\\n')
        f.write(f'🏆 Top 5: {\", \".join(top_symbols) if top_symbols else \"None\"}\\n')
        f.write(f'🎯 Consistent Winners: {winners_count}\\n')
        f.write(f'⚡ Action: {action}\\n')
        f.write(f'📊 Filtered: {len(results)}{trading_metrics}\\n')
        f.write(f'📚 History: {weeks_analyzed} weeks analyzed\\n\\n')
        f.write(f'🤖 Enhanced Bot v2.1 + Auto History - {datetime.now().strftime(\"%H:%M UTC\")}\\n')
    
    print('✅ Commit message con historial generado')
    
except Exception as e:
    print(f'❌ Error generando commit message: {e}')
    # Fallback message
    with open('commit_message.txt', 'w') as f:
        f.write(f'📊 Weekly Analysis + Auto History $REPORT_DATE\\n\\nGenerated by Enhanced Conservative Trading Bot with History Management\\n')
        " REPORT_DATE="$REPORT_DATE"
        
        cat commit_message.txt
        
    - name: Limpiar archivos antiguos con gestión inteligente de historial
      run: |
        echo "🧹 Limpieza automática inteligente de historial..."
        
        # Función para mantener solo N archivos más recientes por tipo
        cleanup_files() {
            local pattern=$1
            local keep_count=$2
            local file_type=$3
            
            echo "📂 Procesando $file_type (patrón: $pattern)..."
            
            # Buscar archivos que coincidan con el patrón
            files=$(ls -t $pattern 2>/dev/null || true)
            
            if [ -z "$files" ]; then
                echo "   ✅ No hay archivos $file_type para procesar"
                return
            fi
            
            # Contar archivos encontrados
            file_count=$(echo "$files" | wc -l)
            echo "   📊 Encontrados: $file_count archivos"
            
            # Si hay menos o igual archivos que el límite, no hacer nada
            if [ $file_count -le $keep_count ]; then
                echo "   ✅ No es necesario limpiar (≤ $keep_count archivos)"
                return
            fi
            
            # Identificar archivos a eliminar (los más antiguos)
            to_delete=$(echo "$files" | tail -n +$((keep_count + 1)))
            deleted_count=0
            
            # Eliminar archivos antiguos
            for file in $to_delete; do
                if [ -f "$file" ]; then
                    echo "   🗑️ Eliminando archivo antiguo: $file"
                    rm -f "$file"
                    deleted_count=$((deleted_count + 1))
                fi
            done
            
            # Mostrar resumen
            remaining=$(ls $pattern 2>/dev/null | wc -l)
            echo "   ✅ $file_type: Eliminados $deleted_count, mantenidos $remaining"
        }
        
        echo ""
        echo "🔄 Iniciando limpieza por categorías con límites optimizados..."
        echo ""
        
        # Limpiar archivos históricos de screening (mantener 6 semanas)
        cleanup_files "weekly_screening_results_*.json" 6 "Screening históricos"
        
        # Limpiar resultados ultra conservadores completos (mantener 6) 
        cleanup_files "ultra_conservative_results_*.json" 6 "Resultados ultra conservadores"
        
        # Limpiar reportes semanales (mantener 4)
        cleanup_files "ENHANCED_WEEKLY_REPORT*.md" 4 "Reportes semanales mejorados"
        cleanup_files "WEEKLY_REPORT*.md" 4 "Reportes semanales estándar"
        
        # Limpiar análisis de consistencia históricos (mantener 4)
        cleanup_files "consistency_analysis_*.json" 4 "Análisis de consistencia"
        
        # Limpiar recomendaciones de rotación históricas (mantener 4)
        cleanup_files "rotation_recommendations_*.json" 4 "Recomendaciones de rotación"
        
        echo ""
        echo "📊 RESUMEN FINAL DE ARCHIVOS:"
        echo "════════════════════════════════════════════════════════════"
        
        # Mostrar archivos actuales (principales del workflow)
        echo "🔑 ARCHIVOS PRINCIPALES (siempre presentes):"
        for main_file in "weekly_screening_results.json" "consistency_analysis.json" "rotation_recommendations.json" "docs/data.json"; do
            if [ -f "$main_file" ]; then
                size=$(stat -c%s "$main_file" 2>/dev/null || echo "unknown")
                echo "   ✅ $main_file ($size bytes)"
            else
                echo "   ❌ $main_file (faltante)"
            fi
        done
        
        echo ""
        echo "📚 ARCHIVOS DE HISTORIAL (gestionados automáticamente):"
        
        # Contar y mostrar archivos históricos
        hist_screening=$(ls weekly_screening_results_*.json 2>/dev/null | wc -l)
        hist_ultra=$(ls ultra_conservative_results_*.json 2>/dev/null | wc -l)
        hist_reports=$(ls *WEEKLY_REPORT*.md 2>/dev/null | wc -l)
        hist_consistency=$(ls consistency_analysis_*.json 2>/dev/null | wc -l)
        hist_rotation=$(ls rotation_recommendations_*.json 2>/dev/null | wc -l)
        
        echo "   📈 Screening históricos: $hist_screening archivos (máx 6)"
        echo "   🔬 Ultra conservadores: $hist_ultra archivos (máx 6)"
        echo "   📋 Reportes: $hist_reports archivos (máx 4)"
        echo "   🔄 Consistencia: $hist_consistency archivos (máx 4)"
        echo "   🎯 Rotación: $hist_rotation archivos (máx 4)"
        
        # Calcular espacio total aproximado
        total_files=$((1 + hist_screening + hist_ultra + hist_reports + hist_consistency + hist_rotation))
        echo ""
        echo "📊 Total archivos en repositorio: ~$total_files"
        echo "💾 Espacio estimado: <50MB (GitHub limit: 1GB)"
        echo ""
        echo "✅ GESTIÓN DE HISTORIAL COMPLETADA"
        echo "   - Archivos principales: Actualizados"
        echo "   - Historial: Mantenido automáticamente"
        echo "   - Limpieza: Aplicada según retención definida"
        echo "   - Próxima ejecución: Sábado $(date -d '+7 days' '+%Y-%m-%d 10:00 España')"
        echo "════════════════════════════════════════════════════════════"
        
    - name: Commit resultados semanales con historial completo
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message_file: commit_message.txt
        file_pattern: 'weekly_screening_results.json weekly_screening_results_*.json consistency_analysis.json consistency_analysis_*.json rotation_recommendations.json rotation_recommendations_*.json docs/data.json *WEEKLY_REPORT*.md ultra_conservative_results*.json'
        
    - name: Configurar Pages
      uses: actions/configure-pages@v4
      
    - name: Subir artefacto de Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: './docs'
        
    - name: Desplegar a GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
      
    - name: Resumen final con gestión de historial
      run: |
        echo "================================="
        echo "✅ ANÁLISIS CONSERVADOR MEJORADO CON HISTORIAL COMPLETADO"
        echo "================================="
        echo "Fecha: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo ""
        echo "📊 Dashboard: ${{ steps.deployment.outputs.page_url }}"
        echo "📋 Reportes: Guardados en repositorio con historial"
        echo "🔄 Próximo análisis: $(date -d '+7 days' '+%Y-%m-%d 10:00 España')"
        echo ""
        echo "🚀 CARACTERÍSTICAS APLICADAS:"
        echo "   ✅ Filtros de entrada flexibles (rebotes MA50)"
        echo "   ✅ Momentum sostenible (rangos por timeframe)"
        echo "   ✅ Scoring balanceado (técnico + R/R)"
        echo "   ✅ Stop-loss dinámico ultra conservador (≤10%)"
        echo "   ✅ Take-profit con media y rangos realistas"
        echo "   ✅ Dashboard con niveles de trading"
        echo "   🆕 GESTIÓN AUTOMÁTICA DE HISTORIAL:"
        echo "       • Archivado automático de análisis anteriores"
        echo "       • Limpieza inteligente (mantiene 4-6 semanas)"
        echo "       • Compatibilidad con múltiples formatos"
        echo "       • Análisis de consistencia con historial real"
        echo "       • Sin intervención manual requerida"
        echo "================================="